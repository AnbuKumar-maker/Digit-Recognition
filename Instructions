To keep this easy no feature localization stage is done. You'll have to shove the image in front of the camera lens so that it's the only feature that it sees.

The MNIST dataset will be used. It is comprised of 60,000 training examples and 10,000 test examples of the handwritten digits 0â€“9 formatted as 28x28-pixel monochrome images.

The last layer is a fully connected layer which maps to 10 categories representing the 10 digits.

We are going to do two things. First we train a network for recognizing digits. Then we used the weights of the network we trained for recognizing live camera feed digits taken from the Raspberry Pi camera.

Before we start all of this however let's install everything we need first. I used Python virtual environments to setup the program. So assuming you have all the programs listed below you can issue:

source ~/.profile 
workon cv
python PiCameraApp.py --picamera 1
So lets get to the details. First let's install a bunch of programs.

Install Tensorflow
pip install tensorflow
Install Keras
pip install keras 
Install Open-CV 3.3
Installation of OpenCV is a bit involved if you need all the optimizations. This means we have to compile it from scratch since the one from pip package manager does not have all the optimizations.

The best tutorial I found is from this link:

https://www.pyimagesearch.com/2017/09/04/raspbian-stretch-install-opencv-3-python-on-your-raspberry-pi/ 
Finally install the picamera with Numpy optimizations.

pip install "picamera[array]" 
Now after we have all the software stack installed on the RPI we have to do some training. The network should be trained on a laptop preferable with a GPU, unless you are a hero who's comfortable with a glacier slow performance and you decide to do that on a RPI.

Training the Network
To train the network run the python file on a laptop by issuing :

python Train_MNIST.py
This assumes that you have Cuda (if using the gpu version) , Tensorflow, Keras and matplotlib installed on your laptop.

The program on this file uses Keras to defines a deep neural network model, compile it and after training and validation phases are done it saves the weights of the network.

At the end the program saves the weights of the network as a.h5 file. This is the file with the network weights that we are going to load on the recognition script running on the RPI to recognize live digit images.

Copy the weight file over to your RPI using either scp or WinSCP.

If you have an NVIDIA GPU, training will take a couple of minutes depending on the compute capability of your card. To leverage the GPU however you'll have to install the GPU version of Tensorflow as well as the CUDA executable from NVIDIA website.Otherwise it may take a bit longer if you are only using the CPU.

Recognizing Live Images of Digits
I ended up testing both handwritten digits and printed digits. Accuracy of prediction depends mostly on lighting and image angle and how ambiguous (read crappy) your writing really is. After you start the app press t to read the digits and q to qui
